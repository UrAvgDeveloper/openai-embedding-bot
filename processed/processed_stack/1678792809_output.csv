title,text
Installation,"Installation. # Installation The core package, , contains only the MachineLearningInterface at about.md and a simple driver that implements the Collective Learning Protocol. To install only the core package: To make collective learning easier to use we have defined extra packages with helpers for model development in Keras and Pytorch. To install with Keras/Pytorch extras: To install both the Keras and Pytorch extras use: To run stand-alone examples: For more examples see the Examples Page at examples.md"
Installation,"Installing From Source. ,Running the tests: Tests can be run with:"
Installation,"Documentation. To run the documentation, first install mkdocs at https://www.mkdocs.org and plugins: Then run:"
Using collective learning,Using collective learning. # Using collective learning This tutorial is a simple guide to trying out the collective learning protocol with your own machine learning code. Everything runs locally. The most flexible way to use the collective learning backends is to make a class that implements the Collective Learning defined in ml_interface.py at {{ repo_root }}/colearn/ml_interface.py. This tutorial will walk through implementing the . If you're already using keras or pytorch you might find it easier to use the or classes. See the other tutorials for details of how to do that.
Using collective learning,"The MachineLearningInterface. There are four methods that need to be implemented: 1. causes the model to do some training and then return a new set of weights that are proposed to the other learners. This method shouldn't charge the current weights of the model - that only happens when is called. 2. - the models takes some new weights and returns a vote on whether the new weights are an improvement. As in propose_weights, this shouldn't change the current weights of the model - that only happens when is called. 3. - the model accepts some weights that have been voted on and approved by the set of learners. The old weighs of the model are discarded and replaced by the new weights. 4. should return the current weights of the model."
Using collective learning,"Algorithms that work with colearn. These conditions need to be fulfilled for algorithms to work with collective learning: * Model fitting must be incremental so that the previous model is used as the starting point for training. This is easy to achieve for neural networks because neural network training is always iterative, but for other learning algorithms more care must be taken. Some examples of getting this wrong: None of the training methods here use the previous result when fit is called for a second time; instead they start again from scratch. Good examples of incremental training can be seen in the examples at ./examples.md. Many sklearn models have a parameter which can be set to to use the previous training result. XGBoost has an parameter for passing in the previous training results. * The model mustn't overfit when propose_weights() is called. You should limit training so that a learner will not overfit their training data in one round. For example, if a learner overfits their own training data then the other learners will reject the proposed update because it is not a good fit for their data. For a neural network a good approach is to restrict the number of batches that are used each round; for random forest, restrict the trees that are added each round."
Using collective learning,"Implementation for fraud detection task. Here is the class that implements the for the task of detecting fraud in bank transactions. Let's step through this and see how it works. The propose_weights method saves the current weights of the model. Then it performs some training of the model, and gets the new weights. It returns the new weights, and resets the model weights to be the old weights. The test_weights method takes as a parameter the proposed weights that it needs to vote on. It saves the current weights of the model, and then sets the model weights to be the proposed weights. It tests the model and votes based on whether the score that it is monitoring has improved. The vote score can be any metric that you like. You could use loss, accuracy, mean squared error or any custom metric. If the vote score is the loss then the model would only vote True if the score has decreased. Here we're using accuracy, so the vote is true if the score increases. This method then resets the weights to the old values and returns the vote along with some scores for monitoring purposes. The accept_weights method sets the weights of the model to be the new weights. It also updates the vote score to be the current performance. !!! Note You could implement a cache here. These weights will already have been tested in test_weights, so the vote score could be retrieved from the cache instead of recomputed. The final method is the simplest - get_current_weights just returns the current weights of the model. These weights are wrapped inside a object."
Using collective learning,"The rest of the example. The data is loaded and preprocessed and then split into equal parts for each learner. Then a list of FraudLearner instances is created, each with its own dataset. Then we give all the models the same weights to start off with: And then we can move on to the final stage, which is training with Collective Learning. The function performs one round of collective learning. One learner is selected to train and propose an update. The other learners vote on the update, and if the vote passes then the update is accepted. Then a new round begins."
How to run the demo,"How to run the demo. # How to run the demo You can try collective learning for yourself using the simple demo in run_demo at {{repo_root }}/colearn_examples/ml_interface/run_demo.py. This demo creates n learners for one of six learning tasks and co-ordinates the collective learning between them. There are six potential models for the demo * KERAS_MNIST is the Tensorflow implementation of a small model for the standard handwritten digits recognition dataset * KERAS_MNIST_RESNET is the Tensorflow implementation of a Resnet model for the standard handwritten digits recognition dataset * KERAS_CIFAR10 is the Tensorflow implementation of the classical image recognition dataset * PYTORCH_XRAY is Pytorch implementation of a binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from Kaggle at https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia * PYTORCH_COVID_XRAY is Pytorch implementation of a 3 class classification task that requires predicting no finding, covid or pneumonia from images of chest X-rays. This dataset is not currently publicly available. * FRAUD The fraud dataset consists of information about credit card transactions, and the task is to predict whether transactions are fraudulent or not. The data need to be downloaded from Kaggle at https://www.kaggle.com/c/ieee-fraud-detection Use the -h flag to see the options: Arguments to run the demo:"
How to run the demo,"Running MNIST. The simplest task to run is MNIST because the data are downloaded automatically from . The command below runs the MNIST task with five learners for 15 rounds. You should see a graph of the vote score and the test score (the score used here is categorical accuracy). The new model is accepted if the fraction of positive votes (green colour) is higher than 0.5. The new model is rejected if the fraction of negative votes (red color) is lower than 0.5. As you can see, there are five learners, and initially they perform poorly. In round one, learner 0 is selected to propose a new set of weights."
How to run the demo,Other datasets. To run the CIFAR10 dataset: The Fraud and X-ray datasets need to be downloaded from kaggle (this requires a kaggle account). To run the fraud dataset: To run the X-ray dataset:
2. Covid X-RAY dataset,2. Covid X-RAY dataset. ï»¿# 1. CIFAR10 dataset
2. Covid X-RAY dataset,"1.1. Information and installation. ,1.1.1. Information about the dataset: * The CIFAR-10 dataset consists of 60000 32x32x3 colour images in 10 classes, with 6000 images per class. * The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks * Input for NN are raw 32x32 3 channels GRB images * NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 * Code folder: here at {{ repo_root }}/colearn_examples/cifar10 * Invoke parameter: -t CIFAR10 ,1.1.2. Requirements: * Cifar dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required"
2. Covid X-RAY dataset,"1.2. Models. ,1.2.1. CIFAR10Conv Keras model: ,1.2.2. CIFAR10Conv2 Keras model: ,1.2.3. CIFAR10Resnet50 Keras model: # 2. Covid X-RAY dataset"
2. Covid X-RAY dataset,"2.1. Information and installation. ,2.1.1. Information about the dataset: * The Covid X-Ray dataset consists of grayscale images, there are 478 covid images and 203 normal images. * To increase the number of images normal/pneumonia dataset is added * Final dataset, which is a combination of two previously mentioned datasets, contains 1434 images, 478 images for each class. * Images are cropped and resized to 512x512 pixel and spatial domain (Texture, GLDM, GLCM) and frequency domain (FFT and Wavelet) features are used to create 256 dimensional vector representation of each image. PCA is applied after to reduce dimensionality to 64 values which represents the first 64 highest eigenvalues of the covariance matrix. * Input for NN are 64 values for each image * NN output is distribution of probabilities for each class i.e. 3 values * Code folder: here at {{ repo_root }}/colearn_examples/covid_xray * Invoke parameter: -t COVID ,2.1.2 Requirements: * Download Covid dataset: here at https://github.com/ieee8023/COVID-chestxray-dataset * Download pneumonia dataset: here at https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
2. Covid X-RAY dataset,"2.2. Models. ,2.2.1. Covid XRAY Keras model: # 3. FRAUD dataset"
2. Covid X-RAY dataset,"3.1. Information and installation. ,3.1.1. Information about the dataset: * EEE-CIS Fraud Detection, contains multiple files with credit card transactions * Raw dataset files are automatically merged and pre-processed and input files for neural network are created * X.csv with data - has 431 values for each transaction * Y.csv with labels - v has 1 value for each transaction * 0 = not a fraud * 1 = fraud * Code folder: here at {{ repo_root }}/colearn_examples/fraud * Invoke parameter: -t FRAUD ,3.1.2. Requirements: * Download dataset: here at https://www.kaggle.com/c/ieee-fraud-detection"
2. Covid X-RAY dataset,"3.2. Models. ,3.2.1. FraudDense1 Keras model: ,3.2.2. FraudSVM Scikit-learn model: * Model is defined as SGDClassifier(max_iter=1, verbose=0, loss=""modified_huber"") * Which is support vector machine linear classifier # 4. MNIST"
2. Covid X-RAY dataset,"4.1. Information and installation. ,4.1.1. Information about the dataset: * This is a dataset of 70,000 28x28x1 grayscale images of the 10 digits * Input for NN are raw 28x28 1 channel images * NN output is distribution of probabilities for each class i.e. 10 values that sums up to 1 * Code folder: here at {{ repo_root }}/colearn_examples/mnist * Invoke parameter: -t MNIST ,4.1.2 Requirements: * MNIST dataset is loaded from tensorflow.keras.datasets.cifar10 and no stored data are required"
2. Covid X-RAY dataset,"4.2. Models. ,4.2.1. MNISTConv Keras model: ,4.2.2. MNIST Pytorch model: ,4.2.3. MNISTSupermini Keras model: # 5. Pneumonia XRAY"
2. Covid X-RAY dataset,"5.1. Information and installation. ,5.1.1. Information about the dataset: * The Chest X-Ray Images (Pneumonia) dataset consists of 5856 grayscale images of various sizes in 2 classes (normal/pneumonia). * Labels are determined by folder name - NORMAL or PNEUMONIA * Input for NN are raw resized 128x128 1 channel images * NN output is distribution of probabilities for each class i.e. 2 values * Code folder: here at {{ repo_root }}/colearn_examples/xray * Invoke parameter: -t XRAY ,5.1.2 Requirements: * Download dataset: here at https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
2. Covid X-RAY dataset,"5.2. Models. ,5.2.1. XraySupermini Keras model #: ,5.2.2. XrayResnet50 Keras model: ,5.2.3. XrayPretrainedResnet50 Keras model: ,5.2.4. XrayDropout Keras model: ,5.2.5. XrayDropout2 Keras model: ,5.2.6. XrayVGG16 Keras model: ,5.2.7. XrayMini Keras model: ,5.2.7. XrayOneMB Keras model:"
Mnist gRPC Example,Mnist gRPC Example. # Mnist gRPC Example To run the Keras Mnist gRPC example run: !!!Note This requires You can verify that the example is working correctly by running the probe: For more about the gRPC components of Colearn see the gRPC Tutorial at grpc_tutorial.md
What is differential privacy?,"What is differential privacy?. # What is differential privacy? To make a machine learning system that protects privacy we first need to have a definition of what privacy is. Differential privacy (DP) is one such definition. First we need to have three concepts: the _database_ is a collection of data about _individuals_ (for example, their medical records), and we want to make a _query_ about that data (for example ""How much does smoking increase someone's risk of cancer?""). DP says that privacy is preserved if the result of the query cannot be used to determine if any particular individual is present in the database. So if person A has their medical data in a database, and the query that we want to make on that database is ""How much does smoking increase someone's risk of cancer"" then the result of that query shouldn't disclose whether or not person A's details are in the database. From this comes the idea of _sensitivity_ of a query. The _sensitivity_ of a query determines how much the result of the query depends on an individual's data. For example, the query ""How much does smoking increase the risk of cancer for adults in the UK?"" is less sensitive than the query ""How much does smoking increase the risk of cancer for men aged 50-55 in Cambridge?"" because the second query uses a smaller set of individuals."
What is differential privacy?,"Epsilon-differential privacy. EDP is a scheme for preserving differential privacy. In EDP all queries have random noise added to them, so they are no longer deterministic. So if the query was ""What fraction of people in the database are male"", and the true result is 0.5 then the results of calling this query three times might be 0.53, 0.49 and 0.51. This makes it harder to tell if an individual's data is in the database, because the effect of adding a person can't be distinguished from the effect of the random noise. Intuitively this is a bit like blurring an image: adding noise obscures personal information. The amount of personal information that is revealed isn't zero, but it is guaranteed to be below a certain threshold. The level of privacy that is provided is controlled by the parameter epsilon; the greater epsilon is the more noise is added and the more privacy is preserved. Queries that are more sensitive have more noise added, because they reveal more information about individuals. It is important to add as little noise as possible, because adding more noise obscures the patterns that you want to extract from the data."
What is differential privacy?,Differential privacy when training neural networks. Each training step for a neural network can be though of as a complicated query on a database of training data. Differential privacy mechanisms tell you how much noise you need to add to guarantee a certain level of privacy. The and libraries implement epsilon-differential privacy for training neural networks for pytorch and keras respectively. # How to use differential privacy with colearn By using and we can make collective learning use differential privacy. The learner that is proposing weights does so using a DP-enabled optimiser. To see an example of using this see dp_pytorch at {{ repo_root }}/colearn_examples/ml_interface/pytorch_mnist_diffpriv.py and dp_keras at {{ repo_root }}/colearn_examples/ml_interface/keras_mnist_diffpriv.py.
MLI Factory,"MLI Factory. # MLI Factory The machine learning interface factory are the minimum methods a client needs to implement to work with the GRPC Server (and become a Learner). There are two main types of functions: - Supported Systems (get_models, get_dataloaders, get_compatibilities) - Get a MachineLearningInterface (get_mli) When the GRPC server is connected to the Orchestrator, it will query the supported system functions to know what the MLI Factory can serve. Later when the Orchestrator wants to run something on this Learner it will call get_mli with a model_arch_name, a dataloader_name and more parameters for both. The object returned is then used to run the experiment through the MLI. ### Supported Systems The supported systems functions get_models and get_dataloaders should return a set of <name, {default parameters dictionary}> which will be stored (not currently implemented) in the api database. The idea being that the user can change these values on the UI while preparing to start/join an experiment. ### ExampleMliFactory An example MLIFactory that will implement all the tasks in run_demo. This is the one used by contract_learn."
How collective learning works,"How collective learning works. # How collective learning works A Colearn experiment begins when a group of entities, referred to as *learners*, decide on a model architecture and begin learning. Together they will train a single global model. The goal is to train a model that performs better than any of the learners can produce by training on their private data set. ### How Training Works Training occurs in rounds; during each round the learners attempt to improve the performance of the global shared model. To do so each round an **update** of the global model (for example new set of weights in a neural network) is proposed. The learners then **validate** the update and decide if the new model is better than the current global model. If enough learners *approve* the update then the global model is updated. After an update is approved or rejected a new round begins. The detailed steps of a round updating a global model *M* are as follows: 1. One of the learners is selected and proposes a new updated model *M'* 2. The rest of the learners **validate** *M'* - If *M'* has better performance than *M* against their private data set then the learner votes to approve - If not, the learner votes to reject 3. The total votes are tallied - If more than some threshold (typically 50%) of learners approve then *M'* becomes the new global model. If not, *M* continues to be the global model 4. A new round begins. By using a decentralized ledger (a blockchain) this learning process can be run in a completely decentralized, secure and auditable way. Further security can be provided by using differential privacy at https://en.wikipedia.org/wiki/Differential_privacy to avoid exposing your private data set when generating an update."
How collective learning works,"Learning algorithms that work for collective learning. Collective learning is not just for neural networks; any learning algorithm that can be trained on subsets of the data and which can use the results of previous training rounds as the basis for subsequent rounds can be used. Neural networks fit both these constraints: training can be done on mini-batches of data and each training step uses the weights of the previous training step as its starting point. More generally, any model that is trained using mini-batch stochastic gradient descent is fine. Other algorithms can be made to work with collective learning as well. For example, a random forest can be trained iteratively by having each learner add new trees (see example in mli_random_forest_iris.py at {{ repo_root }}/examples/mli_random_forest_iris.py). For more discussion, see here at ./intro_tutorial_mli.md."
How collective learning works,"The driver. then sends the proposed weights to each of the learners, and they each vote on whether this is an improvement. If the number of approving votes is greater than the vote threshold the proposed weights are accepted, and if not they're rejected."
How collective learning works,"The Machine Learning Interface. There are four methods that need to be implemented: 1. causes the model to do some training and then return a new set of weights that are proposed to the other learners. This method shouldn't change the current weights of the model - that only happens when is called. 2. - the models takes some new weights and returns a vote on whether the new weights are an improvement. As with propose_weights, this shouldn't change the current weights of the model - that only happens when is called. 3. - the models accepts some weights that have been voted on and approved by the set of learners. The old weights of the model are discarded and replaced by the new weights. 4. should return the current weights of the model. For more details about directly implementing the machine learning interface see the tutorial here at ./intro_tutorial_mli.md"
Examples that use Collective Learning,"Examples that use Collective Learning. # Examples that use Collective Learning This is a list of examples that we've implemented to show you how to use Collective Learning locally. See and example of the gRPC server at grpc_examples.md for the next step towards decentralized Colearn. ### Mnist Uses the standard Mnist at https://en.wikipedia.org/wiki/MNIST_database database of handwritten images * mnist_keras at {{ repo_root }}/colearn_examples/ml_interface/keras_mnist.py. Uses the helper class. Discussed in more detail here at ./intro_tutorial_keras.md. * mnist_pytorch at {{ repo_root }}/colearn_examples/ml_interface/pytorch_mnist.py. Uses the helper class. Discussed in more detail here at ./intro_tutorial_pytorch.md. ### Fraud The fraud dataset consists of information about credit card transactions. The task is to predict whether transactions are fraudulent or not. The data needs to be downloaded from Kaggle at https://www.kaggle.com/c/ieee-fraud-detection, and the data directory passed in with the flag . * fraud_mli at {{ repo_root }}/colearn_examples/ml_interface/mli_fraud.py. Uses the directly and detects fraud in bank transactions. * fraud_keras at {{ repo_root }}/colearn_examples/ml_interface/keras_fraud.py. Loads data from numpy arrays and uses . ### Cifar10 Uses the standard Cifar10 at https://en.wikipedia.org/wiki/CIFAR-10 database of images * cifar_keras at {{ repo_root }}/colearn_examples/ml_interface/keras_cifar.py. Uses the helper class. * cifar_pytorch at {{ repo_root }}/colearn_examples/ml_interface/pytorch_cifar.py. Uses the helper class. ### Xray A binary classification task that requires predicting pneumonia from images of chest X-rays. The data need to be downloaded from Kaggle at https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia, and the data directory passed in with the flag * xray_keras at {{ repo_root }}/colearn_examples/ml_interface/keras_xray.py. Uses the helper class. * xray_pytorch at {{ repo_root }}/colearn_examples/ml_interface/pytorch_xray.py. Uses the helper class. ### Iris Uses the standard Iris dataset. The aim of this task is to classify examples into one of three iris species based on measurements of the flower. * iris_random_forest at {{ repo_root }}/colearn_examples/ml_interface/mli_random_forest_iris.py. Uses the directly and a random forest for classification."
bug_report,"bug_report. --- name: Bug report about: Create a report to help us improve title: '' labels: '' assignees: '' --- Thanks for taking the time to let us know about a bug! Please try to fill in as much as possible of this form so that we can fix it. **Describe the bug** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Desktop (please complete the following information):** - OS: [e.g. iOS] - Version [e.g. 22] **Additional context** Add any other context about the problem here."
